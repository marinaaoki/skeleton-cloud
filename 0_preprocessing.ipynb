{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preprocessing\n",
    "\n",
    "In [1], the authors utilise the NTU RGB+D 60 datasest for their experiments. Each skeleton of the 60-class dataset is captured at 30fps and consists of 25 joints. \n",
    "\n",
    "The preprocessing the authors perform consists of several steps:\n",
    "\n",
    "1. Denoise the raw skeleton data\n",
    "2. Remove skeleton files that contain poor data\n",
    "3. Remove files that contain 2 actors -> this removes 11 action classes\n",
    "\n",
    "The dataset is split into train/test splits depending on camera view. The first camera view is used for evaluations, while the other two are used for training.\n",
    "\n",
    "The sequences are cut or repeated until each sequence has a length of T = 75. However, we leave this to be done dynamically in the Dataloader in case we want to use a different sampling mechanism.\n",
    "\n",
    "### 0.1 Preprocessing\n",
    "\n",
    "We start by loading the raw skeleton data and filtering any samples with missing skeletons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "\n",
    "ntu60_path = '/media/ubi-lab-desktop/Extreme Pro/data/nturgb+d_skeletons'\n",
    "ntu60_files = os.listdir(ntu60_path)\n",
    "\n",
    "with open('sitc/data/NTU_RGBD_samples_with_missing_skeletons.txt', 'r') as f:\n",
    "    missing_skeletons = [line.split(\"\\n\")[0] for line in f.readlines()[3:]]\n",
    "\n",
    "ntu60_files = [file for file in ntu60_files if Path(file).stem not in missing_skeletons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the authors do no specify how the denoising is performed, we will skip this step for now and remove the files that contain 2 actors.\n",
    "with open('sitc/data/NTU_RGBD_actions_with_two_people.txt', 'r') as f:\n",
    "    two_people = [line.split(\"\\n\")[0] for line in f.readlines()]\n",
    "\n",
    "ntu60_files = [file for file in ntu60_files if re.findall('[A-Z][^A-Z]*', Path(file).stem)[-1] not in two_people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in filtered data: 46231\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in filtered data: {len(ntu60_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Data Split Generation\n",
    "\n",
    "We split the data depending on the camera ID, as defined in Section 3.2.2 of [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 30757\n",
      "Number of samples in validation set: 15474\n"
     ]
    }
   ],
   "source": [
    "# To generate the train/test splits, we have to filter the samples of camera 1 for validation, and the samples of cameras 2 and 3 for training.\n",
    "ntu60_train = [file for file in ntu60_files if re.findall('[A-Z][^A-Z]*', Path(file).stem)[1] in ['C002', 'C003']]\n",
    "\n",
    "ntu60_val = [file for file in ntu60_files if re.findall('[A-Z][^A-Z]*', Path(file).stem)[1] in ['C001']]\n",
    "\n",
    "print(f\"Number of samples in training set: {len(ntu60_train)}\")\n",
    "print(f\"Number of samples in validation set: {len(ntu60_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the train/test split file IDs in a .txt file for easy data loading.\n",
    "with open('sitc/data/splits/ntu60_train.txt', 'w') as f:\n",
    "    for file in ntu60_train:\n",
    "        f.write(f\"{Path(file).stem}\\n\")\n",
    "\n",
    "with open('sitc/data/splits/ntu60_val.txt', 'w') as f:\n",
    "    for file in ntu60_val:\n",
    "        f.write(f\"{Path(file).stem}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Data Pairings\n",
    "\n",
    "We have to construct paired samples where two distinct actors ($p$ and $p'$) perform the same two actions ($a$ and $a'$) under an identical camera view.\n",
    "\n",
    "Therefore, we additionally save the IDs of all paired samples in separate .txt files, one for each action-camera pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ntu60_files:\n",
    "    action = re.findall('[A-Z][^A-Z]*', Path(file).stem)[-1]\n",
    "    camera = re.findall('[A-Z][^A-Z]*', Path(file).stem)[1]\n",
    "\n",
    "    with open(f'sitc/data/NTU_RGBD_{camera}_{action}.txt', 'a') as f:\n",
    "        f.write(f\"{Path(file).stem}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: randomly pair together two samples of the same action and camera, different person to create the pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] Carr, T., Xu, D., & Lu, A. (2024). Adversary-guided motion retargeting for skeleton anonymization. arXiv. https://arxiv.org/abs/2405.05428\n",
    "- [2] Shahroudy, A., Liu, J., Ng, T.-T., & Wang, G. (2016). NTU RGB+D: A large scale dataset for 3D human activity analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 1010â€“1019)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
